{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_Eaw-142Scp"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import random\n",
    "import os.path as osp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from_numpy = torch.from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLzItMnZiYY0"
   },
   "source": [
    "# **Data Normalization** \n",
    "Here we load the data and compute the average and std per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYqpWjcEGBYJ"
   },
   "outputs": [],
   "source": [
    "stats_transforms = torchvision.transforms.ToTensor()\n",
    "\n",
    "stats_data = torchvision.datasets.ImageFolder(root='./trainset', \n",
    "                                               transform=stats_transforms)\n",
    "len_data = len(stats_data)\n",
    "stats_loader = torch.utils.data.DataLoader(stats_data, batch_size=1, \n",
    "                                           shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "z_60EM91hArT",
    "outputId": "8add213b-83b0-4fb6-a732-80fd7ecf014a"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for batch in stats_loader:\n",
    "    x, y = batch\n",
    "    images.append(x[0].numpy())\n",
    "    \n",
    "means = np.mean(np.asarray(images), axis=(0,2,3))\n",
    "stds = np.std(np.asarray(images), axis=(0,2,3))\n",
    "print(f'means : {means}')\n",
    "print(f'stds : {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaW7-8Ww2ZzD"
   },
   "outputs": [],
   "source": [
    "## Load data and splits it between train and valid sets\n",
    "SEED = 131214\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "data_size = (3,64,64)\n",
    "batch_size = 64\n",
    "classes_dict = {0:'Cat', 1:'Dog'}\n",
    "distrib_means = (0.48973373, 0.45465815, 0.4159738)\n",
    "distrib_stds = (0.25206217, 0.24510814, 0.24726307)\n",
    "data_augmentation = True\n",
    "\n",
    "# balanced training set as many cats than dogs\n",
    " \n",
    "base_transforms = [torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(distrib_means, distrib_stds)]\n",
    " \n",
    "\n",
    "if data_augmentation:\n",
    "    r_choice = torchvision.transforms.RandomChoice\n",
    "    compose = torchvision.transforms.Compose\n",
    "    augmentations = [torchvision.transforms.RandomHorizontalFlip(),\n",
    "                    torchvision.transforms.RandomResizedCrop(64),\n",
    "                    torchvision.transforms.ColorJitter(brightness=0.2, \n",
    "                                                       contrast=0.2, \n",
    "                                                       saturation=0.2, \n",
    "                                                       hue=0.2),\n",
    "                    torchvision.transforms.RandomRotation(90),\n",
    "                    torchvision.transforms.RandomVerticalFlip()]\n",
    "    \n",
    "    aug_transforms = compose(\n",
    "    [torchvision.transforms.RandomApply([r_choice(augmentations +\n",
    "                   [torchvision.transforms.RandomOrder(augmentations)])], \n",
    "                                        p=1)]\n",
    "        + base_transforms)\n",
    "else:\n",
    "    aug_transforms = compose(base_compose)\n",
    "    \n",
    "base_transforms = compose(base_transforms)\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(len_data))\n",
    "id_split = int(0.9 * len_data)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[:id_split], indices[id_split:]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='./trainset', \n",
    "                                               transform=aug_transforms)\n",
    "\n",
    "valid_data = torchvision.datasets.ImageFolder(root='./trainset', \n",
    "                                               transform=base_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=2, \n",
    "        worker_init_fn = random.seed(SEED))\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=batch_size, sampler=valid_sampler, num_workers=2, \n",
    "        worker_init_fn = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlIv4KPijRax"
   },
   "source": [
    "# **Here we visualize the data modifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2377
    },
    "colab_type": "code",
    "id": "10Cy3BkaSiT_",
    "outputId": "7ede12b3-fb6d-4279-c6cb-ae6f0c07cf3e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "distrib_stds = np.asarray(distrib_stds)\n",
    "distrib_means = np.asarray(distrib_means)\n",
    "\n",
    "aug_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=False, num_workers=2, \n",
    "        worker_init_fn = random.seed(SEED))\n",
    "\n",
    "vanilla_loader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=batch_size, shuffle=False, num_workers=2, \n",
    "        worker_init_fn = random.seed(SEED))\n",
    "\n",
    "def rescale_im(im):\n",
    "    im = im.numpy()\n",
    "    for ch in range(3):\n",
    "        im[ch,:,:] = im[ch,:,:] * distrib_stds[ch] + distrib_means[ch]\n",
    "    im = np.moveaxis(im,0,-1)\n",
    "    return im\n",
    "\n",
    "for batch_a, batch in zip(aug_loader, vanilla_loader):\n",
    "    xa,y = batch_a\n",
    "    x,y = batch\n",
    "  \n",
    "    for ima, im  in zip(xa[:10],x[:10]):\n",
    "        ima = rescale_im(ima)\n",
    "        im = rescale_im(im)\n",
    "        f, axarr = plt.subplots(1,2)\n",
    "        axarr[0].imshow(im)\n",
    "        axarr[1].imshow(ima)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKWZHjc6jeR2"
   },
   "source": [
    "# **Here we define the building blocks of our architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-grxQQ0OrVU_"
   },
   "outputs": [],
   "source": [
    "#### Building blocks\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "## Resnet without batchNorm\n",
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, k=3):\n",
    "        super().__init__()\n",
    "        p = 1 if k == 3 else 2\n",
    "\n",
    "        # Conv Layer 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=out_channels,\n",
    "            kernel_size=(k, k), stride=stride, padding=p)\n",
    "\n",
    "        # Conv Layer 2\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels, out_channels=out_channels,\n",
    "            kernel_size=(k, k), stride=1, padding=p)\n",
    "\n",
    "        # Shortcut connection to downsample residual\n",
    "        self.shortcut = nn.Sequential()  ## equivalent to identity layer\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=(1, 1), stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "      \n",
    "    \n",
    "class ResLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        if in_features != out_features:\n",
    "            self.project_linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inner = self.activation(self.linear(x))\n",
    "        if self.in_features != self.out_features:\n",
    "            skip = self.project_linear(x)\n",
    "        else:\n",
    "            skip = x\n",
    "        return inner + skip\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XcnlqLdj-BG"
   },
   "source": [
    "# **The Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJCZGC7gkcjS"
   },
   "outputs": [],
   "source": [
    "class CIFARResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10, k=3):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.p = 1 if k == 3 else 2\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=64, kernel_size=(k, k),\n",
    "            stride=1, padding=p)\n",
    "\n",
    "        # Create stages 1-4\n",
    "        self.stage1 = self._create_stage(64, 64, stride=1)\n",
    "        self.stage2 = self._create_stage(64, 128, stride=2)\n",
    "        self.stage3 = self._create_stage(128, 256, stride=2)\n",
    "        self.stage4 = self._create_stage(256, 512, stride=2)\n",
    "        self.linear = nn.Linear(2048, num_classes)\n",
    "        self.flatten = nn.Sequential(Flatten())\n",
    "\n",
    "    # A stage is just two residual blocks for ResNet18\n",
    "    def _create_stage(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels, stride, k=self.k),\n",
    "            ResidualBlock(out_channels, out_channels, 1, k=self.k)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.stage1(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "LxMW0PULCRb2",
    "outputId": "d21b1cfb-f11f-4942-af84-a10f952ad540"
   },
   "outputs": [],
   "source": [
    "# building model\n",
    "\n",
    "model_type = 'ResNet_3'\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    print('cuda is available')\n",
    "else:\n",
    "    print('cuda is not available')\n",
    "\n",
    "\n",
    "if model_type == 'MLP':        \n",
    "    model = nn.Sequential(\n",
    "        ResLinear(784, 312),\n",
    "        nn.ReLU(),\n",
    "        ResLinear(312, 312),\n",
    "        nn.ReLU(),\n",
    "        ResLinear(312, 10)\n",
    "    )\n",
    "elif model_type == 'CNN':\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, 5), #1 input channel, 16 output channel, 5x5 kernel\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 16, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        Flatten(),\n",
    "        ResLinear(2704, 100),\n",
    "        nn.ReLU(),\n",
    "        ResLinear(100, 10)\n",
    "    )\n",
    "elif model_type == 'ResNet_3':\n",
    "    model = CIFARResNet18(num_classes=2, k=3)\n",
    "elif model_type == 'ResNet_5':\n",
    "    model = CIFARRestNet18(num_classes=2, k=5)\n",
    "    \n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "summary(model,data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LeeBpHyrzu7"
   },
   "source": [
    "## **Optim parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUlVFGnQJgFp"
   },
   "outputs": [],
   "source": [
    "## Setting the optimizer\n",
    "num_epochs = 200 # number of training epochs\n",
    "lr0 = 0.1\n",
    "#lr0 = 0.02\n",
    "sched = 'on_plateau'\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr0)\n",
    "if sched == 'on_plateau':\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                               factor=0.5, patience=3, \n",
    "                                               mode='max')\n",
    "else:\n",
    "    lr_lambda = lambda epoch: 0.1**(epoch/float(num_epochs))\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZHCEuDtsGPa"
   },
   "source": [
    "# **The Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6nnpO7BJqw7"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # to compute the loss\n",
    "l2_coeff = 5e-4\n",
    "## Defining the evaluation routines\n",
    "def accuracy(proba, y):\n",
    "    correct = torch.eq(proba.max(1)[1], y).sum().type(torch.FloatTensor)\n",
    "    return correct / y.size(0)\n",
    "  \n",
    "def evaluate(dataset_loader, criterion):\n",
    "    LOSSES = 0\n",
    "    COUNTER = 0\n",
    "    for batch in dataset_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = batch\n",
    "        if model_type == 'MLP':\n",
    "            x = x.view(-1,784)\n",
    "            y = y.view(-1)\n",
    "        elif model_type == 'CNN':\n",
    "            x = x.view(-1,*data_size)\n",
    "            y = y.view(-1)\n",
    "            \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "        loss = criterion(model(x), y)\n",
    "        n = y.size(0)\n",
    "        LOSSES += loss.sum().data.cpu().numpy() * n\n",
    "        COUNTER += n\n",
    "    \n",
    "    return LOSSES / float(COUNTER)\n",
    "\n",
    "def L2_loss(coeff):\n",
    "    l = Variable(torch.FloatTensor(1), requires_grad=True).cuda()\n",
    "    for w in model.named_parameters():\n",
    "        if 'weight' in w[0]:\n",
    "            l = l + 0.5*torch.pow(w[1], 2).sum()\n",
    "    return l*coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bVzyjvtsMoM"
   },
   "source": [
    "# **The Training routine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU0o472lJvJd"
   },
   "outputs": [],
   "source": [
    "store_every = 1000\n",
    "## Defines the train function\n",
    "def train_model():\n",
    "    root_path = f'./'\n",
    "    LOSSES = 0\n",
    "    COUNTER = 0\n",
    "    ITERATIONS = 0\n",
    "    learning_curve_nll_train = list()\n",
    "    learning_curve_nll_valid = list()\n",
    "    learning_curve_acc_train = list()\n",
    "    learning_curve_acc_valid = list()\n",
    "    best_acc = -np.inf\n",
    "    for e in range(num_epochs):\n",
    "        print(f'============= EPOCH {e} ========================')\n",
    "        if not sched=='on_plateau':\n",
    "            scheduler.step()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x, y = batch\n",
    "            if model_type == 'MLP':\n",
    "                x = x.view(-1,784)\n",
    "                y = y.view(-1)\n",
    "            elif model_type == 'CNN':\n",
    "                x = x.view(-1,*data_size)\n",
    "                y = y.view(-1)\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "           \n",
    "            loss = criterion(model(x), y)\n",
    "            if l2_coeff is not None:\n",
    "                loss = loss + L2_loss(l2_coeff)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n = y.size(0)\n",
    "            LOSSES += loss.sum().data.cpu().numpy() * n\n",
    "            COUNTER += n\n",
    "            ITERATIONS += 1\n",
    "            if ITERATIONS%(store_every/5) == 0:\n",
    "                avg_loss = LOSSES / float(COUNTER)\n",
    "                LOSSES = 0\n",
    "                COUNTER = 0\n",
    "                print(\" Iteration {}: TRAIN {}\".format(\n",
    "                    ITERATIONS, avg_loss))\n",
    "        \n",
    "            if ITERATIONS%(store_every) == 0:     \n",
    "                \n",
    "                train_loss = evaluate(train_loader, criterion)\n",
    "                learning_curve_nll_train.append(train_loss)\n",
    "                valid_loss = evaluate(valid_loader, criterion)\n",
    "                learning_curve_nll_valid.append(valid_loss)\n",
    "                \n",
    "                train_acc = evaluate(train_loader, accuracy)\n",
    "                learning_curve_acc_train.append(train_acc)\n",
    "                valid_acc = evaluate(valid_loader, accuracy)\n",
    "                learning_curve_acc_valid.append(valid_acc)\n",
    "                if round(valid_acc,3) > best_acc:\n",
    "                    best_acc = round(valid_acc,3)\n",
    "                    path_to_best = root_path + \n",
    "                    'd_aug'*int(data_augmentation) + \n",
    "                    f'_test_acc_{best_acc}_vanilla2.pth'\n",
    "                    torch.save(model, path_to_best)\n",
    "                    print('saved model')\n",
    "                        \n",
    "                print(\" [NLL] TRAIN {} / TEST {}\".format(\n",
    "                    train_loss, valid_loss))\n",
    "                print(\" [ACC] TRAIN {} / TEST {}\".format(\n",
    "                    train_acc, valid_acc))\n",
    "                if sched=='on_plateau':\n",
    "                    scheduler.step(valid_acc)\n",
    "        \n",
    "        \n",
    "    return learning_curve_nll_train, \\\n",
    "           learning_curve_nll_valid, \\\n",
    "           learning_curve_acc_train, \\\n",
    "           learning_curve_acc_valid, path_to_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtW6qrC4JyMw"
   },
   "outputs": [],
   "source": [
    "nll_train, nll_valid, acc_train, acc_valid, p_best = train_model()\n",
    "import pickle \n",
    "fp=open('./summary.pckl','wb')\n",
    "pickle.dump([nll_train, nll_valid, acc_train, acc_valid, p_best], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AekKs0asb4t"
   },
   "source": [
    "# **Loss Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yI7XBql7rhSr"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "fp=open('./summary.pckl','rb')\n",
    "nll_train, nll_valid, acc_train, acc_valid, p_best = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vABUje0yFz90"
   },
   "outputs": [],
   "source": [
    "d_epoch = store_every/len(train_loader)\n",
    "epoch = d_epoch * np.arange(len(nll_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "O3ZDOVZrPg8g",
    "outputId": "19cacfea-4029-4c48-ec6d-88bebf34e262"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(epoch, nll_train, label='train')\n",
    "ax1.plot(epoch, nll_valid, label='valid')\n",
    "ax1.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "ax1.set_title('Negative Log_likelihood')\n",
    "\n",
    "ax2.plot(epoch, 1-np.asarray(acc_train), label='train')\n",
    "ax2.plot(epoch, 1-np.asarray(acc_valid), label='valid')\n",
    "ax2.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "ax2.set_title('Error rate')\n",
    "ax2.set_xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k59pXjy1slfr"
   },
   "source": [
    "# **Generating the submission file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-1x5VIcPodD"
   },
   "outputs": [],
   "source": [
    "#model = torch.load(p_best)\n",
    "#model.eval()\n",
    "model.load_state_dict(torch.load(\n",
    "    './models/0.938.pthe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXHEWza656U4"
   },
   "outputs": [],
   "source": [
    "class IdImageFolder(torchvision.datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "         Args:\n",
    "             index (int): Index\n",
    "\n",
    "         Returns:\n",
    "             tuple: (image, target) where target is class_index of the target class.\n",
    "         \"\"\"\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        p, n = osp.split(path)\n",
    "        n = n.split('.')[0]\n",
    "        return img, target, n\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0Q7oDqaQj1B"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dogNcat_transforms = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(distrib_means, distrib_stds)])\n",
    "\n",
    "dogNcat_test = IdImageFolder(root='./testset', \n",
    "                                    transform=dogNcat_transforms)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dogNcat_test, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxfrRGMq88e3"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('submission.csv', mode='w') as csv_file:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for batch in test_loader:\n",
    "        x,y,id = batch\n",
    "        x = x.cuda()\n",
    "        raw_labels = model(x).max(1)[1].cpu().numpy()\n",
    "        for i, l in zip(id, raw_labels):\n",
    "            writer.writerow({'id':i, 'label':classes_dict[l]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Majority vote classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_models = './models/'\n",
    "model_list = ['0.94.pthe', 'l2_0.926.pthe', '0.926.pthe', '0.939.pthe',\n",
    "              '0.938.pthe', 'retrain_0.938.pthe']\n",
    "model_list = [root_models + m for m in model_list]\n",
    "\n",
    "models = [CIFARResNet18(num_classes=2).cuda() for _ in model_list]\n",
    "\n",
    "for m, eval in zip(models, model_list):\n",
    "    m.load_state_dict(torch.load(eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('submission_multi.csv', mode='w') as csv_file:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for batch in test_loader:\n",
    "        x,y,id = batch\n",
    "        x = x.cuda()\n",
    "        group_labels=[m(x).max(1)[1].cpu().numpy() for m in models]\n",
    "        raw_labels = []\n",
    "        for i in range(len(id)):\n",
    "            n_p = [0,0]\n",
    "            for j in range(len(group_labels)):\n",
    "                n_p[group_labels[j][i]]+=1\n",
    "            raw_labels.append(np.argmax(n_p))\n",
    "        for i, l in zip(id, raw_labels):\n",
    "            writer.writerow({'id':i, 'label':classes_dict[l]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgy4rnVps3Up"
   },
   "source": [
    "# **Error analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjpWtac4s6I9"
   },
   "outputs": [],
   "source": [
    "dogNcat_error = IdImageFolder(root='./trainset', \n",
    "                              transform=dogNcat_transforms)\n",
    "error_loader = torch.utils.data.DataLoader(dogNcat_error, batch_size=64, \n",
    "                                           shuffle=True, num_workers=2)\n",
    "def softmax(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp / exp.sum()\n",
    "\n",
    "def show_random_misclassified_image(dataset_loader, n_b=3):\n",
    "    ii=0\n",
    "    for batch in dataset_loader:\n",
    "        ii+=1\n",
    "        x, y, n = batch\n",
    "        if model_type == 'CNN':\n",
    "            x = x.view(-1, *data_size)\n",
    "            y = y.view(-1)\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        predictions = model(x)\n",
    "        for i, a in enumerate(torch.eq(predictions.max(1)[1], y)):\n",
    "            if not a:\n",
    "                image_name = n[i]\n",
    "                class_index = int(y[i].data.cpu().numpy())\n",
    "                class_name = classes_dict[class_index]\n",
    "                print('Image name:', image_name)\n",
    "                print('Label:', class_name)\n",
    "                prediction_percentages = softmax(predictions[i].detach().cpu().numpy())\n",
    "                prediction_percentages = np.round(prediction_percentages * 1000) / 10\n",
    "                print(f'Prediction: [Cat:', prediction_percentages[0], \n",
    "                      '%, Dog:', prediction_percentages[1], '%]')\n",
    "                im = rescale_im(x[i].cpu())\n",
    "                plt.imshow(im)\n",
    "                return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "nKocfGMFs_Td",
    "outputId": "a470021a-8456-4b7a-f104-69d7fed08ff5"
   },
   "outputs": [],
   "source": [
    "show_random_misclassified_image(error_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ZR-feswtTjs"
   },
   "source": [
    "# **Kernel Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "colab_type": "code",
    "id": "xGrIGygytXgi",
    "outputId": "b4aa5d7b-0ca8-4df5-f8bc-00bad7549e08"
   },
   "outputs": [],
   "source": [
    "def visualize_kernels():\n",
    "    for i, child in enumerate(model.children()):\n",
    "        data = child.weight.cpu().data.numpy()\n",
    "        data = np.moveaxis(data, 1, -1)\n",
    "        print('Min value in all kernels:', data.min())\n",
    "        print('Max value in all kernels:', data.max())\n",
    "        for k in range(data.shape[0]):\n",
    "            min_value = data[k].min()\n",
    "            max_value = data[k].max()\n",
    "            data[k] = data[k] - min_value\n",
    "            data[k] = data[k] * (1 / data[k].max())\n",
    "            max_value = data[k].max()\n",
    "            min_value = data[k].min()\n",
    "        print('New min value in all kernels:', data.min())\n",
    "        print('New max value in all kernels:', data.max())\n",
    "        plot_kernels(data)\n",
    "        return\n",
    "\n",
    "def plot_kernels(tensor, num_cols=8):\n",
    "    if not tensor.ndim==4:\n",
    "        raise Exception(\"assumes a 4D tensor\")\n",
    "    if not tensor.shape[-1]==3:\n",
    "        raise Exception(\"last dim needs to be 3 to plot\")\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols*1.25,num_rows*1.25))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.set_title(i+1)\n",
    "        ax1.imshow(tensor[i])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.35)\n",
    "    plt.show()\n",
    "\n",
    "visualize_kernels()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "L2_ResNet_N_DataAug_Ass1_q3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
